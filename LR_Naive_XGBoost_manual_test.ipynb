{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Kaggle dataset not found. Proceeding with Cleveland dataset only.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rajar\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [06:37:09] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.83\n",
      "XGBoost Model Accuracy: 0.87\n",
      "Naïve Bayes Accuracy: 0.88\n",
      "Models and Scaler saved successfully!\n",
      "\n",
      "Enter the following test parameters:\n",
      "\n",
      "--- Logistic Regression ---\n",
      "Prediction: Heart Disease Found\n",
      "Risk Level: High Risk\n",
      "Probability: 1.00\n",
      "\n",
      "--- XGBoost Model ---\n",
      "Prediction: No Heart Disease\n",
      "Risk Level: Moderate Risk\n",
      "Probability: 0.47\n",
      "\n",
      "--- Naïve Bayes ---\n",
      "Prediction: Heart Disease Found\n",
      "Risk Level: High Risk\n",
      "Probability: 1.00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Kaggle Dataset\n",
    "try:\n",
    "    kaggle_file_path = \"heart.csv\"\n",
    "    df_kaggle = pd.read_csv(kaggle_file_path)\n",
    "    print(\"Kaggle dataset loaded with shape:\", df_kaggle.shape)\n",
    "except FileNotFoundError:\n",
    "    print(\"Warning: Kaggle dataset not found. Proceeding with Cleveland dataset only.\")\n",
    "    df_kaggle = None\n",
    "\n",
    "# Load and Clean the Cleveland Dataset\n",
    "cleveland_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data\"\n",
    "column_names = [\"age\", \"sex\", \"cp\", \"trestbps\", \"chol\", \"fbs\", \n",
    "                \"restecg\", \"thalach\", \"exang\", \"oldpeak\", \"slope\", \n",
    "                \"ca\", \"thal\", \"target\"]\n",
    "df_cleveland = pd.read_csv(cleveland_url, names=column_names)\n",
    "\n",
    "df_cleveland.replace('?', np.nan, inplace=True)\n",
    "df_cleveland.dropna(inplace=True)\n",
    "df_cleveland = df_cleveland.astype(float)\n",
    "df_cleveland[\"target\"] = df_cleveland[\"target\"].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# Combine Datasets\n",
    "if df_kaggle is not None:\n",
    "    df_combined = pd.concat([df_kaggle, df_cleveland], ignore_index=True)\n",
    "else:\n",
    "    df_combined = df_cleveland.copy()\n",
    "\n",
    "# Prepare Data\n",
    "X = df_combined.drop(columns=[\"target\"])\n",
    "y = df_combined[\"target\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train Logistic Regression\n",
    "log_reg = LogisticRegression(random_state=42, solver='liblinear')\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "y_pred_log = log_reg.predict(X_test_scaled)\n",
    "accuracy_log = accuracy_score(y_test, y_pred_log)\n",
    "print(f\"Logistic Regression Accuracy: {accuracy_log:.2f}\")\n",
    "\n",
    "# Train XGBoost\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\", random_state=42)\n",
    "xgb_model.fit(X_train_scaled, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test_scaled)\n",
    "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "print(f\"XGBoost Model Accuracy: {accuracy_xgb:.2f}\")\n",
    "\n",
    "# Train Naïve Bayes\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train_scaled, y_train)\n",
    "y_pred_nb = nb_model.predict(X_test_scaled)\n",
    "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
    "print(f\"Naïve Bayes Accuracy: {accuracy_nb:.2f}\")\n",
    "\n",
    "# Save Models and Scaler\n",
    "joblib.dump(log_reg, \"log_reg_model.pkl\")\n",
    "joblib.dump(xgb_model, \"xgb_model.pkl\")\n",
    "joblib.dump(nb_model, \"nb_model.pkl\")\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "print(\"Models and Scaler saved successfully!\")\n",
    "\n",
    "# Define Risk Level Function\n",
    "def risk_level(prob):\n",
    "    if prob < 0.4:\n",
    "        return \"Low Risk\"\n",
    "    elif 0.4 <= prob < 0.7:\n",
    "        return \"Moderate Risk\"\n",
    "    else:\n",
    "        return \"High Risk\"\n",
    "\n",
    "# Manual Testing Function\n",
    "def manual_test():\n",
    "    print(\"\\nEnter the following test parameters:\")\n",
    "    try:\n",
    "        values = [float(input(f\"{col}: \")) for col in X.columns]\n",
    "    except ValueError:\n",
    "        print(\"Invalid input. Please enter numeric values where appropriate.\")\n",
    "        return\n",
    "\n",
    "    input_data = pd.DataFrame([values], columns=X.columns)\n",
    "    input_scaled = scaler.transform(input_data)\n",
    "    \n",
    "    # Predictions\n",
    "    prob_log = log_reg.predict_proba(input_scaled)[:, 1][0]\n",
    "    prob_xgb = xgb_model.predict_proba(input_scaled)[:, 1][0]\n",
    "    prob_nb = nb_model.predict_proba(input_scaled)[:, 1][0]\n",
    "    \n",
    "    print(\"\\n--- Logistic Regression ---\")\n",
    "    print(f\"Prediction: {'Heart Disease Found' if prob_log >= 0.5 else 'No Heart Disease'}\")\n",
    "    print(f\"Risk Level: {risk_level(prob_log)}\")\n",
    "    print(f\"Probability: {prob_log:.2f}\")\n",
    "\n",
    "    print(\"\\n--- XGBoost Model ---\")\n",
    "    print(f\"Prediction: {'Heart Disease Found' if prob_xgb >= 0.5 else 'No Heart Disease'}\")\n",
    "    print(f\"Risk Level: {risk_level(prob_xgb)}\")\n",
    "    print(f\"Probability: {prob_xgb:.2f}\")\n",
    "    \n",
    "    print(\"\\n--- Naïve Bayes ---\")\n",
    "    print(f\"Prediction: {'Heart Disease Found' if prob_nb >= 0.5 else 'No Heart Disease'}\")\n",
    "    print(f\"Risk Level: {risk_level(prob_nb)}\")\n",
    "    print(f\"Probability: {prob_nb:.2f}\")\n",
    "\n",
    "# Run Manual Test\n",
    "manual_test()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
